{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58vAjFfg-wHY",
        "outputId": "cac17e51-a217-4385-a879-8a7ae62566d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m397.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post7.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post7-py3-none-any.whl size=2950 sha256=7a7aa25c5c92612b9dd0e24a05ab382e406c87a0122563d41cddc4d58e39ae11\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/9c/85/72901eb50bc4bc6e3b2629378d172384ea3dfd19759c77fd2c\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post7\n",
            "Collecting gradio\n",
            "  Downloading gradio-3.39.0-py3-none-any.whl (19.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: aiohttp~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.8.5)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.100.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client>=0.3.0 (from gradio)\n",
            "  Downloading gradio_client-0.3.0-py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.2/294.2 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio)\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.14.0 (from gradio)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.0.0)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio)\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.22.4)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.10.12)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.27.1)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.7.1)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.3.0->gradio) (2023.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (3.12.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (4.65.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio)\n",
            "  Downloading mdit_py_plugins-0.3.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.8-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.7-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.6-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.5-py3-none-any.whl (39 kB)\n",
            "INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading mdit_py_plugins-0.2.4-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.3-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.2-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.1-py3-none-any.whl (38 kB)\n",
            "  Downloading mdit_py_plugins-0.2.0-py3-none-any.whl (38 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading mdit_py_plugins-0.1.0-py3-none-any.whl (37 kB)\n",
            "Collecting markdown-it-py[linkify]>=2.0.0 (from gradio)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (8.1.6)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio)\n",
            "  Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.7.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.19.3)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx->gradio) (1.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=ef6c70d371994ddce8a466eb8de0e1b6d13ca255772aa499eb0726bff8895609\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, semantic-version, python-multipart, orjson, markdown-it-py, h11, aiofiles, uvicorn, starlette, mdit-py-plugins, huggingface-hub, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: mdit-py-plugins\n",
            "    Found existing installation: mdit-py-plugins 0.4.0\n",
            "    Uninstalling mdit-py-plugins-0.4.0:\n",
            "      Successfully uninstalled mdit-py-plugins-0.4.0\n",
            "Successfully installed aiofiles-23.1.0 fastapi-0.100.1 ffmpy-0.3.1 gradio-3.39.0 gradio-client-0.3.0 h11-0.14.0 httpcore-0.17.3 httpx-0.24.1 huggingface-hub-0.16.4 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 orjson-3.9.2 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 starlette-0.27.0 uvicorn-0.23.2 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install -q openai\n",
        "!pip install -q sklearn\n",
        "!pip install -q gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cA_L-s9--mrh"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import openai\n",
        "import requests\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
        "from termcolor import colored\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "\n",
        "GPT_MODEL = \"gpt-3.5-turbo-0613\"\n",
        "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
        "\n",
        "openai.api_key = open(\"key.txt\", \"r\").read().strip(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MroMKrLO-mrl"
      },
      "outputs": [],
      "source": [
        "@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3))\n",
        "def chat_completion_request(messages, functions=None, model=GPT_MODEL):\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
        "    }\n",
        "    json_data = {\"model\": model, \"messages\": messages}\n",
        "    if functions is not None:\n",
        "        json_data.update({\"functions\": functions})\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            \"https://api.openai.com/v1/chat/completions\",\n",
        "            headers=headers,\n",
        "            json=json_data,\n",
        "        )\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(\"Unable to generate ChatCompletion response\")\n",
        "        print(f\"Exception: {e}\")\n",
        "        return e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vU_Qs9b-mrm"
      },
      "outputs": [],
      "source": [
        "def pretty_print_conversation(messages):\n",
        "    role_to_color = {\n",
        "        \"system\": \"red\",\n",
        "        \"user\": \"green\",\n",
        "        \"assistant\": \"blue\",\n",
        "        \"function\": \"magenta\",\n",
        "    }\n",
        "\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"system\":\n",
        "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"user\":\n",
        "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
        "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
        "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
        "        elif message[\"role\"] == \"function\":\n",
        "            print(colored(f\"function ({message['name']}): {message['content']}\\n\", role_to_color[message[\"role\"]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sznWPDHJ-mro"
      },
      "outputs": [],
      "source": [
        "functions = [\n",
        "    {\n",
        "        \"name\": \"get_bests_houses\",\n",
        "        \"description\": \"\"\"Utiliza esta función para ayudar al cliente a encontrar las casas que mejor\n",
        "        se adapten a sus necesidades y preferencias. Asegúrate de que cualquier valor monetario esté expresado en pesos chilenos. Si el\n",
        "        usuario proporciona un valor en otra moneda, solicita que lo convierta antes de usarlo como parámetro.\"\"\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"description\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"\"\"Una descripción detallada de lo que el usuario busca en una casa.\n",
        "                    Incluye información sobre preferencias personales, ubicación deseada y cualquier característica específica que desee.\n",
        "                    No incluir valores monetarios aquí.\"\"\",\n",
        "                },\n",
        "                \"min_price\": {\n",
        "                    \"type\": \"number\",\n",
        "                    \"description\": \"\"\"El precio mínimo o cantidad mínima de dinero que el usuario está dispuesto a pagar por una\n",
        "                     casa. Debe estar en pesos chilenos.\"\"\",\n",
        "                },\n",
        "                \"max_price\" : {\n",
        "                    \"type\": \"number\",\n",
        "                    \"description\": \"\"\"El precio máximo o cantidad máxima de dinero que el usuario está dispuesto a pagar por una casa. Debe estar\n",
        "                    en pesos chilenos.\"\"\"\n",
        "                },\n",
        "                \"nRooms\": {\n",
        "                    \"type\": \"number\",\n",
        "                    \"description\": \"\"\"El número de habitaciones que el usuario espera que tenga la casa.\"\"\"\n",
        "                }\n",
        "            },\n",
        "\n",
        "            \"required\": [\"description\"],\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"simulacion_hipotecaria\",\n",
        "        \"description\" : \"\"\"Utiliza esta función para simular un crédito hipotecario del cliente. Antes de ejecutar la función el cliente debe validar que los parámetros\n",
        "        que ingresó y tu, como asistente virtual entendiste, son correctos. Si y solo si el cliente valida, se puede ejecutar esta función. No debes asumir nunca un valor.\n",
        "        Si el valor de la casa está en UF, el cliente debe validarlo. Si el valor está en pesos, el cliente debe validarlo.\"\"\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"unidad_moneda\": {\n",
        "                    \"type\": \"number\",\n",
        "                    \"description\": \"\"\"El tipo de moneda que está utilizando para realizar la simulación. Por ejemplo: UF, pesos chilenos, pesos colombianos.\"\"\"\n",
        "                },\n",
        "                \"valor_propiedad\": {\n",
        "                    \"type\": \"number\",\n",
        "                    \"description\": \"\"\"Valor de la propiedad que quiere simular. Por ejemplo: 1000 (si está en UF), 97800000 (si está en pesos), etc.\"\"\"\n",
        "                },\n",
        "                \"monto_pie\": {\n",
        "                    \"type\": \"number\",\n",
        "                    \"description\": \"\"\"El porcentaje en decimal de lo que se quiere pagar de pie para la propiedad. Este valor siempre debe estár en su versión decimal,\n",
        "                    Si el usuario lo ofrece en su versión porcentual, debes transformarlo\"\"\"\n",
        "                },\n",
        "                \"plazo_pago\": {\n",
        "                    \"type\": \"number\",\n",
        "                    \"description\": \"\"\"El plazo de pagos que el cliente quiere para realizar la simulación. Este valor está en años. Solo se pueden valores enteros.\"\"\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"unidad_moneda\", \"valor_propiedad\",\"monto_pie\",\"plazo_pago\"]\n",
        "        }\n",
        "    }\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TXMIStCEAFr"
      },
      "outputs": [],
      "source": [
        "with open('casas.json', 'r') as file:\n",
        "    casas = json.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNetEfsjMtxT"
      },
      "source": [
        "# Vectorización de texto\n",
        "Función que convierte texto en vectores.\n",
        "En base a la posición en la que se encuentren los vectores dentro del plano, se puede ver el grado de similitud que tiene con otros vectores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCaQPWdrMswc"
      },
      "outputs": [],
      "source": [
        "@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3))\n",
        "def embedding_request(text):\n",
        "    response = openai.Embedding.create(input=text, model=EMBEDDING_MODEL)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpItDS09NzvS"
      },
      "source": [
        "# Filtrado de casas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIwCE54eN3SF"
      },
      "outputs": [],
      "source": [
        "def rooms_filter(houses, nRooms):\n",
        "  if nRooms is not None:\n",
        "        houses = [house for house in houses if house['habitaciones'] == nRooms ]\n",
        "  return houses\n",
        "\n",
        "def price_filter(houses, min_price=0, max_price=None):\n",
        "    if min_price is None:\n",
        "        min_price = 0;\n",
        "    houses = [house for house in houses if int(house['precio'].replace(\"$\", \"\").replace(\",\", \"\")) >= min_price and (max_price is None or int(house['precio'].replace(\"$\", \"\").replace(\",\", \"\")) <= max_price)]\n",
        "    return houses\n",
        "\n",
        "def description_filter (houses, description):\n",
        "  emb_res_ref = embedding_request(description)\n",
        "  emb_ref = emb_res_ref[\"data\"][0][\"embedding\"]\n",
        "\n",
        "  descriptions_json = [item['descripcion'] for item in houses]\n",
        "  embeddings_results = []\n",
        "\n",
        "  for house_description in descriptions_json:\n",
        "      res_house = embedding_request(house_description)\n",
        "      embedding_house = res_house[\"data\"][0][\"embedding\"]\n",
        "      embeddings_results.append(embedding_house)\n",
        "\n",
        "  similarity_scores = cosine_similarity([emb_ref], embeddings_results)[0]\n",
        "\n",
        "  sorted_houses = [(houses[i], similarity_scores[i]) for i in range(len(similarity_scores))]\n",
        "  sorted_houses.sort(key=lambda x: x[1], reverse=True)\n",
        "  return sorted_houses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fwXejad-mrp"
      },
      "outputs": [],
      "source": [
        "def get_best_descriptions(props):\n",
        "    print(props)\n",
        "    min_price = props.get('min_price', None)\n",
        "    max_price = props.get('max_price', None)\n",
        "    filtered_houses = casas\n",
        "\n",
        "    if max_price is not None:\n",
        "        filtered_houses = price_filter(filtered_houses, min_price, max_price)\n",
        "\n",
        "    nRooms = props.get('nRooms', None)\n",
        "\n",
        "    if(nRooms is not None):\n",
        "        filtered_houses = rooms_filter(filtered_houses, nRooms)\n",
        "\n",
        "    description = props.get('description', None)\n",
        "\n",
        "    if(len(filtered_houses) != 0):\n",
        "        if(description is not None):\n",
        "          filtered_houses = description_filter(filtered_houses, description)\n",
        "        return filtered_houses\n",
        "    else:\n",
        "        return \"No se encontraron casas con los parámetros indicados\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eA3BdJY3bwt"
      },
      "outputs": [],
      "source": [
        "def simulacion_hipoteca(props):\n",
        "    unidadMoneda = props.get('unidad_moneda', None)\n",
        "    valorPropiedad = props.get('valor_propiedad', None)\n",
        "    montoPie = props.get('monto_pie', None)\n",
        "    plazoPago = props.get('plazo_pago', None)\n",
        "\n",
        "    return \"Simulación realizada. Por favor espere.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEpJ3cEy-mrq"
      },
      "outputs": [],
      "source": [
        "def chat_completion_with_function_execution(messages, functions=[None]):\n",
        "    \"\"\"This function makes a ChatCompletion API call with the option of adding functions\"\"\"\n",
        "    response = chat_completion_request(messages, functions)\n",
        "    print(\"Respuesta antes del error:\")\n",
        "    print(response)\n",
        "    full_message = response.json()[\"choices\"][0]\n",
        "    if full_message[\"finish_reason\"] == \"function_call\":\n",
        "        print(f\"Function generation requested, calling function\")\n",
        "        return call_functions(messages, full_message)\n",
        "\n",
        "    else:\n",
        "        print(f\"Function not required, responding to user\")\n",
        "        return response.json()\n",
        "\n",
        "def call_functions(messages, full_message):\n",
        "    \"\"\"Function calling function which executes function calls when the model believes it is necessary.\n",
        "    Currently extended by adding clauses to this if statement.\"\"\"\n",
        "    if full_message[\"message\"][\"function_call\"][\"name\"] == \"get_bests_houses\":\n",
        "        parsed_output = json.loads(\n",
        "            full_message[\"message\"][\"function_call\"][\"arguments\"]\n",
        "        )\n",
        "        results = get_best_descriptions(parsed_output)\n",
        "        messages.append({\n",
        "            \"role\": \"function\",\n",
        "            \"name\": full_message[\"message\"][\"function_call\"][\"name\"],\n",
        "            # \"content\": str(results),\n",
        "            \"content\": str(results),\n",
        "        })\n",
        "        response = chat_completion_request(messages)\n",
        "        return response.json()\n",
        "    if full_message[\"message\"][\"function_call\"][\"name\"] == \"simulacion_hipoteca\":\n",
        "        parsed_output = json.loads(\n",
        "            full_message[\"message\"][\"function_call\"][\"arguments\"]\n",
        "        )\n",
        "        results = simulacion_hipoteca(parsed_output)\n",
        "        messages.append({\n",
        "            \"role\": \"function\",\n",
        "            \"name\": full_message[\"message\"][\"function_call\"][\"name\"],\n",
        "            \"content\": str(results),\n",
        "        })\n",
        "        response = chat_completion_request(messages)\n",
        "        return response.json()\n",
        "    else:\n",
        "        raise Exception(\"Function does not exist and cannot be called\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ovwQFP2-mrr"
      },
      "outputs": [],
      "source": [
        "class Conversation:\n",
        "    def __init__(self):\n",
        "        self.conversation_history = []\n",
        "\n",
        "    def add_message(self, role, content):\n",
        "        message = {\"role\": role, \"content\": content}\n",
        "        self.conversation_history.append(message)\n",
        "\n",
        "    def display_conversation(self, detailed=False):\n",
        "        role_to_color = {\n",
        "            \"system\": \"red\",\n",
        "            \"user\": \"green\",\n",
        "            \"assistant\": \"blue\",\n",
        "            \"function\": \"magenta\",\n",
        "        }\n",
        "        for message in self.conversation_history:\n",
        "            print(\n",
        "                colored(\n",
        "                    f\"{message['role']}: {message['content']}\\n\\n\",\n",
        "                    role_to_color[message[\"role\"]],\n",
        "                )\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLjiHUTz-mrr"
      },
      "outputs": [],
      "source": [
        "paper_system_message = \"\"\"Eres HSI o Home Search Inteligence. Eres un chatbot de asistencia\n",
        "que se encarga de encontrar la mejor casa para un usuario y también simular créditos hipotecarios.\n",
        "Al ejecutar una función no debes asumir parámetros nunca. Si el cliente no proporciona un valor que es requerido, debes señalarlo.\n",
        "También, considera que si el usuario ingresa un precio, valor o cualquier tipo de unidad monetaria, debe señalar qué tipo de unidad está utilizando, como UF's o pesos chilenos\"\"\"\n",
        "\n",
        "paper_conversation = Conversation()\n",
        "paper_conversation.add_message(\"system\", paper_system_message)\n",
        "# paper_conversation.add_message(\"system\", \"Soy HSI o Home Search Intelligence, un chatbot de asistencia inmobiliaria especializado en simulación de créditos hipotecarios. Mi función es ayudarte a encontrar la mejor casa y proporcionarte información sobre créditos. No asumo datos y solo trabajo con valores en UF's o pesos chilenos. ¿En qué puedo ayudarte hoy?\")\n",
        "# paper_conversation.add_message(\"system\", \"Recuerda que como HSI, no tomo decisiones por ti. Siempre señalaré si necesito más información o si alguna entrada es requerida para realizar una simulación de crédito hipotecario. No dudes en proporcionar los valores en UF's o pesos chilenos para una mejor precisión en las respuestas.\")\n",
        "# paper_conversation.add_message(\"system\", \"Como asistente especializado en créditos hipotecarios, puedo responder preguntas sobre tasas de interés, plazos de pago y cuotas mensuales. Si tienes alguna duda o deseas simular un crédito, no dudes en consultarme. Recuerda que solo trabajo con valores en UF's o pesos chilenos. Estoy aquí para ayudarte en todo momento.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pvSbj_pGUYa"
      },
      "outputs": [],
      "source": [
        "def chatbot_response(user_input, history):\n",
        "    history = history or []\n",
        "    paper_conversation.add_message(\"user\", user_input)\n",
        "    chat_response = chat_completion_with_function_execution(\n",
        "        paper_conversation.conversation_history, functions=functions\n",
        "    )\n",
        "    assistant_message = chat_response[\"choices\"][0][\"message\"][\"content\"]\n",
        "    paper_conversation.add_message(\"assistant\", assistant_message)\n",
        "    history.append((user_input, assistant_message))\n",
        "    return history,history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "gCKomQJ4GvpJ",
        "outputId": "5db7093c-7694-4b67-afb8-a86d767929b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://525f9c890f59bde5d9.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://525f9c890f59bde5d9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Respuesta antes del error:\n",
            "<Response [200]>\n",
            "Function not required, responding to user\n",
            "Respuesta antes del error:\n",
            "<Response [200]>\n",
            "Function generation requested, calling function\n",
            "{'description': 'Necesito una casa con el mejor precio posible'}\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://525f9c890f59bde5d9.gradio.live\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chatbot = gr.Chatbot()\n",
        "iface = gr.Interface(\n",
        "    chatbot_response,    # La función que maneja las respuestas del chatbot\n",
        "    [\"text\", \"state\"],\n",
        "    [chatbot, \"state\"],\n",
        "    allow_flagging=\"never\",\n",
        "    title=\"Home Search Inteligence\"\n",
        ")\n",
        "iface.launch(share=True, debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}